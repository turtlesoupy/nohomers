{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, \"../nohomers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import json\n",
    "from pathlib import Path\n",
    "from lightweight_gan import Trainer\n",
    "from lightweight_gan.lightweight_gan import slerp\n",
    "from uuid import uuid4\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import tempfile\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import ffmpeg\n",
    "import shutil\n",
    "import copy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trainer(\n",
    "    data='./data',\n",
    "    results_dir='./results',\n",
    "    models_dir='./models',\n",
    "    name='default',\n",
    "    new=False,\n",
    "    load_from=-1,\n",
    "    image_size=256,\n",
    "    optimizer='adam',\n",
    "    fmap_max=512,\n",
    "    transparent=False,\n",
    "    batch_size=10,\n",
    "    gradient_accumulate_every=4,\n",
    "    num_train_steps=150000,\n",
    "    learning_rate=2e-4,\n",
    "    save_every=1000,\n",
    "    evaluate_every=1000,\n",
    "    generate=False,\n",
    "    generate_interpolation=False,\n",
    "    attn_res_layers=[32],\n",
    "    sle_spatial=False,\n",
    "    disc_output_size=1,\n",
    "    antialias=False,\n",
    "    interpolation_num_steps=100,\n",
    "    save_frames=False,\n",
    "    num_image_tiles=8, \n",
    "    trunc_psi=0.75,\n",
    "    aug_prob=None,\n",
    "    aug_types=['cutout', 'translation'],\n",
    "    dataset_aug_prob=0.,\n",
    "    multi_gpus=False,\n",
    "    calculate_fid_every=None,\n",
    "    seed=42,\n",
    "    amp=False\n",
    "):\n",
    "    def cast_list(el):\n",
    "        return el if isinstance(el, list) else [el]\n",
    "\n",
    "    model_args = dict(\n",
    "        name=name,\n",
    "        results_dir=results_dir,\n",
    "        models_dir=models_dir,\n",
    "        batch_size=batch_size,\n",
    "        gradient_accumulate_every=gradient_accumulate_every,\n",
    "        attn_res_layers=cast_list(attn_res_layers),\n",
    "        sle_spatial=sle_spatial,\n",
    "        disc_output_size=disc_output_size,\n",
    "        antialias=antialias,\n",
    "        image_size=image_size,\n",
    "        optimizer=optimizer,\n",
    "        fmap_max=fmap_max,\n",
    "        transparent=transparent,\n",
    "        lr=learning_rate,\n",
    "        save_every=save_every,\n",
    "        evaluate_every=evaluate_every,\n",
    "        trunc_psi=trunc_psi,\n",
    "        aug_prob=aug_prob,\n",
    "        aug_types=cast_list(aug_types),\n",
    "        dataset_aug_prob=dataset_aug_prob,\n",
    "        calculate_fid_every=calculate_fid_every,\n",
    "        amp=amp\n",
    "    )\n",
    "\n",
    "    ret = Trainer(**model_args)\n",
    "    ret.load(load_from)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate_image_with_latents(self, num=1):\n",
    "    self.GAN.eval()\n",
    "    latent_dim = self.GAN.latent_dim\n",
    "    image_size = self.GAN.image_size\n",
    "    latents = torch.randn((num, latent_dim)).cuda(self.rank)\n",
    "    generated_images = self.generate_truncated(self.GAN.GE, latents)\n",
    "    return list(\n",
    "        (latents[i, :], transforms.ToPILImage()(generated_images[i, :, :, :].cpu()))\n",
    "        for i in range(num)\n",
    "    )\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_interpolation_frames(self, latents_low, latents_high, num_frames):\n",
    "    self.GAN.eval()\n",
    "    num_rows = 1\n",
    "\n",
    "    latent_dim = self.GAN.latent_dim\n",
    "    image_size = self.GAN.image_size\n",
    "\n",
    "    # latents and noise\n",
    "\n",
    "    #latents_low = torch.randn(num_rows ** 2, latent_dim).cuda(self.rank)\n",
    "    #latents_high = torch.randn(num_rows ** 2, latent_dim).cuda(self.rank)\n",
    "    ratios = torch.linspace(0., 1., num_frames) \n",
    "\n",
    "    batch_size = latents_low.shape[0]\n",
    "    \n",
    "    ret = [list() for _ in range(batch_size)]\n",
    "    \n",
    "    for i, ratio in enumerate(ratios):\n",
    "        if i == 0:\n",
    "            interp_latents = latents_low\n",
    "        elif i == len(ratios) - 1:\n",
    "            interp_latents = latents_high\n",
    "        else:\n",
    "            interp_latents = slerp(ratio, latents_low, latents_high)\n",
    "        generated_images = self.generate_truncated(self.GAN.GE, interp_latents)\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            ret[i].append(transforms.ToPILImage()(generated_images[i, :, :, :].cpu()))\n",
    "    \n",
    "    return ret\n",
    "\n",
    "def frames_to_video(frames, output_path, fps=30, bitrate=\"1M\"):\n",
    "    with tempfile.TemporaryDirectory() as td:\n",
    "        for i, frame in enumerate(frames):\n",
    "            frame.save(Path(td) / f\"{i:06d}.jpg\")\n",
    "            \n",
    "        (\n",
    "            ffmpeg\n",
    "            .input(f'{td}/*.jpg', pattern_type='glob', framerate=fps)\n",
    "            .output(filename=output_path, video_bitrate=bitrate)\n",
    "            .overwrite_output()\n",
    "            .run()\n",
    "        )\n",
    "\n",
    "\n",
    "def gen_images_and_manifest(trainer, output_base_dir, num=10):\n",
    "    image_output_dir = Path(output_base_dir) / \"images\"\n",
    "    image_output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    image_objects = []\n",
    "    image_and_latents = list(generate_image_with_latents(trainer, num=num))\n",
    "    for latent, image in image_and_latents:\n",
    "        name = f\"{uuid4()}.jpg\"\n",
    "        image.save(str(image_output_dir / name))\n",
    "        image_objects.append({\n",
    "            \"image_name\": name,\n",
    "            \"latent\": list(float(e) for e in latent.cpu().numpy()), \n",
    "        })\n",
    "        \n",
    "    return image_objects\n",
    "\n",
    "\n",
    "def gen_interpolation_videos(trainer, manifest, output_base_dir, per_edge=1, video_duration=3.0, video_fps=30):\n",
    "    assert len(manifest) > per_edge\n",
    "    \n",
    "    num_frames = int(video_fps * video_duration)\n",
    "    \n",
    "    videos_path = Path(output_base_dir) / \"videos\"\n",
    "    videos_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    out_manifest = copy.deepcopy(manifest)\n",
    "    for src_i, src in enumerate(out_manifest):\n",
    "        dest_set = set()\n",
    "        while len(dest_set) < per_edge:\n",
    "            i = random.randint(0, len(manifest) - 1)\n",
    "            if i != src_i:\n",
    "                dest_set.add(i)\n",
    "                \n",
    "        transition_items = []\n",
    "        \n",
    "        src_latent = torch.tensor(src[\"latent\"]).unsqueeze(0).cuda()\n",
    "        for dst_i in dest_set:\n",
    "            dst = out_manifest[dst_i]\n",
    "            dst_latent = torch.tensor(dst[\"latent\"]).unsqueeze(0).cuda()\n",
    "            \n",
    "            video_name = f\"{src['image_name']}_to_{dst['image_name']}.mp4\"\n",
    "            \n",
    "            \n",
    "            # This works in batches\n",
    "            video_frames = generate_interpolation_frames(\n",
    "                trainer, \n",
    "                latents_low=src_latent,\n",
    "                latents_high=dst_latent,\n",
    "                num_frames=num_frames,\n",
    "            )\n",
    "            \n",
    "            frames_to_video(video_frames[0], output_path=videos_path / video_name, fps=video_fps, bitrate=\"1M\")\n",
    "            \n",
    "            transition_items.append({\n",
    "                \"dest_index\": dst_i,\n",
    "                \"dest_name\": dst[\"image_name\"],\n",
    "                \"video_name\": str(video_name),\n",
    "            })\n",
    "            \n",
    "        src[\"transitions\"] = transition_items\n",
    "    return out_manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from version 0.12.4\n"
     ]
    }
   ],
   "source": [
    "trainer = get_trainer(\n",
    "    models_dir=\"/mnt/evo/projects/metapedia/tmp/stylegan2/models\", \n",
    "    name=\"simpsons_bart_homer_new_cleaned_1024\",\n",
    "    load_from=24,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(\"/mnt/evo/projects/nohomers/tmp\")\n",
    "shutil.rmtree(output_dir, ignore_errors=False, onerror=None)\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "manifest = gen_images_and_manifest(trainer, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_manifest = gen_interpolation_videos(trainer, manifest, output_dir, per_edge=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest_path = Path(output_dir) / \"manifest.json\"\n",
    "with open(manifest_path, \"w\") as f:\n",
    "    json.dump(video_manifest, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = generate_interpolation_frames(\n",
    "    trainer, \n",
    "    latents_low=image_and_latents[0][0].unsqueeze(0),\n",
    "    latents_high=image_and_latents[1][0].unsqueeze(0),\n",
    "    num_frames=120,\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_to_video(test, output_dir / \"test.mp4\", fps=30, bitrate=\"0.5M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print((output_dir / \"test.mp4\").exists())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
