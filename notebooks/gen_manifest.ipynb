{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, \"../nohomers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import json\n",
    "from pathlib import Path\n",
    "from lightweight_gan import Trainer\n",
    "from lightweight_gan.lightweight_gan import slerp\n",
    "from uuid import uuid4\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import tempfile\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trainer(\n",
    "    data='./data',\n",
    "    results_dir='./results',\n",
    "    models_dir='./models',\n",
    "    name='default',\n",
    "    new=False,\n",
    "    load_from=-1,\n",
    "    image_size=256,\n",
    "    optimizer='adam',\n",
    "    fmap_max=512,\n",
    "    transparent=False,\n",
    "    batch_size=10,\n",
    "    gradient_accumulate_every=4,\n",
    "    num_train_steps=150000,\n",
    "    learning_rate=2e-4,\n",
    "    save_every=1000,\n",
    "    evaluate_every=1000,\n",
    "    generate=False,\n",
    "    generate_interpolation=False,\n",
    "    attn_res_layers=[32],\n",
    "    sle_spatial=False,\n",
    "    disc_output_size=1,\n",
    "    antialias=False,\n",
    "    interpolation_num_steps=100,\n",
    "    save_frames=False,\n",
    "    num_image_tiles=8,\n",
    "    trunc_psi=0.75,\n",
    "    aug_prob=None,\n",
    "    aug_types=['cutout', 'translation'],\n",
    "    dataset_aug_prob=0.,\n",
    "    multi_gpus=False,\n",
    "    calculate_fid_every=None,\n",
    "    seed=42,\n",
    "    amp=False\n",
    "):\n",
    "    def cast_list(el):\n",
    "        return el if isinstance(el, list) else [el]\n",
    "\n",
    "    model_args = dict(\n",
    "        name=name,\n",
    "        results_dir=results_dir,\n",
    "        models_dir=models_dir,\n",
    "        batch_size=batch_size,\n",
    "        gradient_accumulate_every=gradient_accumulate_every,\n",
    "        attn_res_layers=cast_list(attn_res_layers),\n",
    "        sle_spatial=sle_spatial,\n",
    "        disc_output_size=disc_output_size,\n",
    "        antialias=antialias,\n",
    "        image_size=image_size,\n",
    "        optimizer=optimizer,\n",
    "        fmap_max=fmap_max,\n",
    "        transparent=transparent,\n",
    "        lr=learning_rate,\n",
    "        save_every=save_every,\n",
    "        evaluate_every=evaluate_every,\n",
    "        trunc_psi=trunc_psi,\n",
    "        aug_prob=aug_prob,\n",
    "        aug_types=cast_list(aug_types),\n",
    "        dataset_aug_prob=dataset_aug_prob,\n",
    "        calculate_fid_every=calculate_fid_every,\n",
    "        amp=amp\n",
    "    )\n",
    "\n",
    "    ret = Trainer(**model_args)\n",
    "    ret.load(load_from)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate_image_with_latents(self, num=1):\n",
    "    self.GAN.eval()\n",
    "    latent_dim = self.GAN.latent_dim\n",
    "    image_size = self.GAN.image_size\n",
    "    latents = torch.randn((num, latent_dim)).cuda(self.rank)\n",
    "    generated_images = self.generate_truncated(self.GAN.G, latents)\n",
    "    return list(\n",
    "        (latents[i, :], transforms.ToPILImage()(generated_images[i, :, :, :].cpu()))\n",
    "        for i in range(num)\n",
    "    )\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_interpolation_frames(self, latents_low, latents_high, num_frames):\n",
    "    self.GAN.eval()\n",
    "    num_rows = 1\n",
    "\n",
    "    latent_dim = self.GAN.latent_dim\n",
    "    image_size = self.GAN.image_size\n",
    "\n",
    "    # latents and noise\n",
    "\n",
    "    #latents_low = torch.randn(num_rows ** 2, latent_dim).cuda(self.rank)\n",
    "    #latents_high = torch.randn(num_rows ** 2, latent_dim).cuda(self.rank)\n",
    "    ratios = torch.linspace(0., 1., num_frames)\n",
    "\n",
    "    batch_size = latents_low.shape[0]\n",
    "    \n",
    "    ret = [list() for _ in range(batch_size)]\n",
    "    \n",
    "    for i, ratio in enumerate(ratios):\n",
    "        if i == 0:\n",
    "            interp_latents = latents_low\n",
    "        elif i == len(ratios) - 1:\n",
    "            interp_latents = latents_high\n",
    "        else:\n",
    "            interp_latents = slerp(ratio, latents_low, latents_high)\n",
    "        generated_images = self.generate_truncated(self.GAN.GE, interp_latents)\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            ret[i].append(transforms.ToPILImage()(generated_images[i, :, :, :].cpu()))\n",
    "    \n",
    "    return ret\n",
    "\n",
    "def frames_to_video(frames, output_path, fps=30, bitrate=\"1M\"):\n",
    "    with tempfile.TemporaryDirectory() as td:\n",
    "        for i, frame in enumerate(frames):\n",
    "            frame.save(Path(td) / f\"{i:06d}.jpg\")\n",
    "            \n",
    "        (\n",
    "            ffmpeg\n",
    "            .input(f'{td}/*.jpg', pattern_type='glob', framerate=fps)\n",
    "            .output(filename=output_path, video_bitrate=bitrate)\n",
    "            .overwrite_output()\n",
    "            .run()\n",
    "        )\n",
    "\n",
    "\n",
    "def gen_images_and_manifest(trainer, output_base_dir, num=10):\n",
    "    image_output_dir = Path(output_base_dir) / \"images\"\n",
    "    image_output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    #video_output_dir = Path(output_base_dir) / \"videos\"\n",
    "\n",
    "    manifest_path = Path(output_base_dir) / \"manifest.json\"\n",
    "   \n",
    "    \n",
    "    image_objects = []\n",
    "    image_and_latents = list(generate_image_with_latents(trainer, num=num))\n",
    "    for latent, image in image_and_latents:\n",
    "        name = f\"{uuid4()}.jpg\"\n",
    "        image.save(str(image_output_dir / name))\n",
    "        image_objects.append({\n",
    "            \"image_name\": name,\n",
    "            \"latent\": list(float(e) for e in latent.cpu().numpy()), \n",
    "        })\n",
    "        \n",
    "\n",
    "    with open(manifest_path, \"w\") as f:\n",
    "        json.dump(image_objects, f)\n",
    "    \n",
    "    return image_objects, image_and_latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from version 0.12.4\n"
     ]
    }
   ],
   "source": [
    "trainer = get_trainer(\n",
    "    models_dir=\"/mnt/evo/projects/metapedia/tmp/stylegan2/models\", \n",
    "    name=\"simpsons_bart_homer_new_cleaned_256_lightweight_aug04_all\",\n",
    "    load_from=15,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(\"/mnt/evo/projects/nohomers/tmp\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "outputs, image_and_latents = gen_images_and_manifest(\n",
    "    trainer, output_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "generate_interpolation_frames() got an unexpected keyword argument 'video_bitrate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-167-856848bafd90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m test = generate_interpolation_frames(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlatents_low\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_and_latents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlatents_high\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_and_latents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnum_frames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nohomers/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: generate_interpolation_frames() got an unexpected keyword argument 'video_bitrate'"
     ]
    }
   ],
   "source": [
    "test = generate_interpolation_frames(\n",
    "    trainer, \n",
    "    latents_low=image_and_latents[0][0].unsqueeze(0),\n",
    "    latents_high=image_and_latents[1][0].unsqueeze(0),\n",
    "    num_frames=120,\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_to_video(test, output_dir / \"test.mp4\", fps=30, bitrate=\"0.5M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print((output_dir / \"test.mp4\").exists())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
